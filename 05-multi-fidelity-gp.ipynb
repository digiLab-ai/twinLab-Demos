{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multi-Fidelity Gaussian Process**\n",
    "\n",
    "In many engineering and physics modelling tasks, one may have data coming from not only a \"high-fidelity\" source of information, but also one or several sources of \"low-fidelity\" data.\n",
    "\n",
    "Typically, the high-fidelity data comes from some expensive processes such as long-running simulation codes, or real-world empirical experiments. This cost factor may render the collection of comprehensive training data for surrogate modelling to be impractical or impossible, such that only a few high-fidelity data samples exist. By contrast, low-fidelity data is typically generated from much cheaper (but much less accurate) processes. This means that low-fidelity data is plentiful, but often of limited usefulness for inference, since the data only correlates with the behaviour of the true process.\n",
    "\n",
    "In these scenarios, `twinlab` provides a number of multi-fidelity surrogate modelling approaches, which allows the user to model a surrogate of the high-fidelity process using only a small amount of high-fidelity data and a large amount of low-fidelity data.\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "- Multi-fidelity Gaussian Process\n",
    "- Multi-fidelity Gaussian Process with observation noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinlab imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Formulation**\n",
    "\n",
    "Here, we will formulate a true function from which we have a small amount of high-fidelity data, and another function which only correlates with the true function, but from which we can generate a large amount of low-fidelity data.\n",
    "\n",
    "In particular, we will generate 10 training samples from the high-fidelity model, and 100 samples from the low-fidelity model. In reality, the ratio between the number of available samples of the high- and low-fidelity data may be much worse than a factor of 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high fidelity model with one output\n",
    "def model(x):\n",
    "    return (6 * x - 2) ** 2 * np.sin(12 * x - 4)\n",
    "\n",
    "\n",
    "# Define reduced fidelity model with one output\n",
    "def reduced_model(x):\n",
    "    return 0.5 * model(x) + 10 * (x - 0.5) + 5\n",
    "\n",
    "\n",
    "X = np.linspace(0, 1)\n",
    "y = model(X)\n",
    "y_reduced = reduced_model(X)\n",
    "\n",
    "# Generate data\n",
    "X_data = np.random.uniform(size=10)\n",
    "y_data = model(X_data)\n",
    "\n",
    "X_data_reduced = np.random.uniform(size=100)\n",
    "y_data_reduced = reduced_model(X_data_reduced)\n",
    "\n",
    "X_test = np.random.uniform(size=5)\n",
    "y_test = model(X_test)\n",
    "\n",
    "# Generate fidelity data\n",
    "data_fidelity = np.hstack((np.ones(10), 0.5 * np.ones(100), np.ones(5)))\n",
    "\n",
    "# Save to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": np.hstack((X_data, X_data_reduced, X_test)),\n",
    "        \"y\": np.hstack((y_data, y_data_reduced, y_test)),\n",
    "        \"fidelity\": np.hstack((np.ones(10), 0.5 * np.ones(100), 1 * np.ones(5))),\n",
    "    }\n",
    ")\n",
    "\n",
    "df.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in order for the Gaussian Process model to be able to distinguish between which data sample is low- or high-fidelity, we have to include this information in the data table. In this case, we chose to call this column `'fidelity'`, and indicated the fidelity information by giving `fidelity=1.0` for high-fidelity data samples, and `fidelity=0.5` to indicate the low-fidelity data samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "plt.plot(X, y, label=\"True function\", c=\"C0\")\n",
    "plt.scatter(X_data, y_data, c=\"C0\")\n",
    "\n",
    "plt.plot(X, y_reduced, label=\"Reduced function\", c=\"C1\")\n",
    "plt.scatter(X_data_reduced, y_data_reduced, c=\"C1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset_id = \"FidelityGP_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multifidelity GP Campaign**\n",
    "\n",
    "In `twinlab`, a multifidelity GP model is exposed via the keyword argument `estimator_type=\"fixed_noise_gp\"` provided to the `campaign_params` dictionary during initialisation. In addition, a `\"fidelity\"` keyword parameter at initialisation which denotes the name of the column containing the fidelity information is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"FidelityGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,  # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": [\n",
    "        \"x\"\n",
    "    ],  # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.75,  # Determine how much data is used for training, here 75% is used to train the model\n",
    "    \"estimator\": \"gaussian_process_regression\",  # and 25% is used to test it.\n",
    "    \"fidelity\": \"fidelity\",\n",
    "    \"estimator_kwargs\": {\n",
    "        \"estimator_type\": \"multi_fidelity_gp\",  # Keyword string to request multifidelity model\n",
    "    },\n",
    "}\n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inference results\n",
    "df_mean, df_stdev = tl.predict_campaign(pd.DataFrame(X, columns=[\"x\"]), campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values\n",
    "\n",
    "plt.fill_between(\n",
    "    X.flatten(),\n",
    "    (y_mean - 1.96 * y_stdev).flatten(),\n",
    "    (y_mean + 1.96 * y_stdev).flatten(),\n",
    "    color=\"k\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "plt.scatter(df[\"x\"], df[\"y\"], alpha=0.5, label=\"Training Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.plot(X, y, c=\"r\", linewidth=2, label=\"True Function\")\n",
    "plt.plot(X, y_mean, c=\"k\", linewidth=2, linestyle=\"dashed\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multifidelity GP Campaign with homoskedastic noise**\n",
    "\n",
    "In some instances, one may have observation noise associated with the data observations. In this case, one can still use a multi-fidelity model, however a new `DataFrame` called `df_stdev` must be provided to `tl.train_campaign`, containing the standard deviation of the observation noise/error. This additional table must contain the same columns as the mean data. Additionally, the key `'estimator_type': 'fixed_noise_multi_fidelity_gp'` should be provided to the `campaign_params` dictionary during initialisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisy = df.copy(deep=True)\n",
    "\n",
    "# Add noise to data\n",
    "noise_scale = 0.2\n",
    "df_noisy[\"y\"] = df_noisy[\"y\"] + np.random.normal(\n",
    "    scale=noise_scale, size=len(df_noisy[\"y\"])\n",
    ")\n",
    "\n",
    "# Generate observation noise dataframe\n",
    "df_stdev = pd.DataFrame({\"y\": np.ones(len(df_noisy[\"y\"])) * noise_scale})\n",
    "\n",
    "plt.plot(X, y)\n",
    "plt.scatter(df_noisy[\"x\"].values, df_noisy[\"y\"].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset_id = \"Noisy_FidelityGP_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_noisy, dataset_id, verbose=True)\n",
    "\n",
    "# Define the name of the dataset\n",
    "dataset_std_id = \"Noisy_FidelityGP_STD_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_stdev, dataset_std_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"Noisy_FidelityGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"dataset_std_id\": dataset_std_id,\n",
    "    \"inputs\": [\"x\"],\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.75,\n",
    "    \"estimator\": \"gaussian_process_regression\",\n",
    "    \"fidelity\": \"fidelity\",\n",
    "    \"estimator_kwargs\": {\n",
    "        \"estimator_type\": \"fixed_noise_multi_fidelity_gp\",  # Keyword string to request homoskedastic model\n",
    "    },\n",
    "}\n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inference results\n",
    "df_mean, df_stdev = tl.predict_campaign(pd.DataFrame(X, columns=[\"x\"]), campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values\n",
    "\n",
    "plt.fill_between(\n",
    "    X.flatten(),\n",
    "    (y_mean - 1.96 * y_stdev).flatten(),\n",
    "    (y_mean + 1.96 * y_stdev).flatten(),\n",
    "    color=\"k\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "plt.scatter(df[\"x\"], df[\"y\"], alpha=0.5, label=\"Training Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.plot(X, y, c=\"r\", linewidth=2)\n",
    "plt.plot(X, y_mean, c=\"k\", linewidth=2, linestyle=\"dashed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaigns and datasets\n",
    "tl.delete_campaign(\"FidelityGP\")\n",
    "tl.delete_campaign(\"Noisy_FidelityGP\")\n",
    "\n",
    "tl.delete_dataset(\"Noisy_FidelityGP_Data\")\n",
    "tl.delete_dataset(\"Noisy_FidelityGP_STD_Data\")\n",
    "tl.delete_dataset(\"FidelityGP_Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-T1BT2Sfn-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
