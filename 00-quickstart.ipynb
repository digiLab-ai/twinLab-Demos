{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quickstart Guide**\n",
    "\n",
    "This guide covers the standard usage pattern and basic functionality to help you get started with twinLab. In this jupyter notebook we will:\n",
    "\n",
    "    1. Upload a dataset to twinLab.\n",
    "    2. Use `tl.train_campaign` to create a surrogate model.\n",
    "    3. Use the model to make a prediction with `tl.predict_campaign`.\n",
    "    4. Visualise the results and their uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **API setup**\n",
    "\n",
    "The first time you use twinLab you will have to enter your API key and confirm you have the correct URL set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key\n",
    "tl.set_api_key(\"my_api_key\")\n",
    "\n",
    "# Check which URL is being used\n",
    "tl.get_server_url()\n",
    "\n",
    "# Set the server URL\n",
    "tl.set_server_url(\"http://twinlab.digilab.co.uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Your twinLab information**\n",
    "\n",
    "Confirm your twinLab version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.get_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And view your user information, including how many credits you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.get_user_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Upload a dataset**\n",
    "\n",
    "Datasets must be data presented as a `pandas.DataFrame` object, or a filepaths which points to a csv file that can be parsed to a `pandas.DataFrame` object. **Both must be formatted with clearly labelled columns.** Here, we will label the input (predictor) variable `x` and the output variable `y`. In `twinlab`, data is expected to be in column-feature format, meaning each row represents a single data sample, and each column represents a data feature. \n",
    "\n",
    "Datasets must be uploaded with a `dataset_id` which is used to access them from the cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.6964691855978616,\n",
    "0.28613933495037946,\n",
    "0.2268514535642031,\n",
    "0.5513147690828912,\n",
    "0.7194689697855631,\n",
    "0.42310646012446096,\n",
    "0.9807641983846155,\n",
    "0.6848297385848633,\n",
    "0.48093190148436094,\n",
    "0.3921175181941505]\n",
    "\n",
    "y = [-0.8173739564129022,\n",
    "0.8876561174050408,\n",
    "0.921552660721474,\n",
    "-0.3263338765412979,\n",
    "-0.8325176123242133,\n",
    "0.4006686354731812,\n",
    "-0.16496626502368078,\n",
    "-0.9607643657025954,\n",
    "0.3401149876855609,\n",
    "0.8457949914442409]\n",
    "\n",
    "# Creating the dataframe using the above arrays\n",
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "# View the dataset before uploading\n",
    "display(df)\n",
    "\n",
    "# Define the name of the dataset\n",
    "dataset_id = \"example_data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data is stored in a csv file the you must input the filepath string into `tl.upload_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepath = \"example_data_folder/example_data.csv\"\n",
    "\n",
    "# Define the name of the dataset\n",
    "dataset_id = \"example_data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_filepath, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train a campaign**\n",
    "\n",
    "The `campaign` class is used to train and implement your surrogate models. As with datasets, an id is defined, this is what the model will be saved as in the cloud. When training a model the arguments are passed using a dictionary; here we name that dictionary `campaign_params`. To train the model we use the `tl.train_campaign` function, inputting the dictionary and `campaign_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_id = \"example_campaign\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,       # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": [\"x\"],                # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.8         # Determine how much data is used for training, here 80% is used to train the model  \n",
    "}                                   # and 20% is used to test it.     \n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using a predict campaign**\n",
    "\n",
    "The surrogate model is now trained and saved to the cloud under the `campaign_id`. It can now be used to make predictions. First define a dataset of inputs for which you want to find outputs; ensure that this is a `pandas.DataFrame` object or a file path for a correctly formatted csv. Then call `tl.predict_campaign` with the keyword arguments being the evaluation dataset and the `campaign_id` of the model you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs for the dataset\n",
    "x_eval = np.linspace(0,1,128)\n",
    "\n",
    "# Convert to a dataframe\n",
    "df_eval = pd.DataFrame({'x':x_eval})\n",
    "display(df_eval)\n",
    "\n",
    "# Predict the results\n",
    "df_mean, df_std = tl.predict_campaign(df_eval, campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively the dataset can be input from a correctly formatted csv using its filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The define the file path of the csv\n",
    "df_eval_filepath = \"example_data_folder/example_eval_data.csv\"\n",
    "\n",
    "# Predict the results\n",
    "df_mean, df_std = tl.predict_campaign(df_eval, campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Viewing the results**\n",
    "\n",
    "`tl.predict_campaign` outputs mean values for each input and their standard deviation; this gives the abilty to nicely visualise the uncertainty in results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "# nsigs = [0.674, 1.960, 2.576]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "# Plot results\n",
    "grid = df_eval[\"x\"]\n",
    "mean = df_mean[\"y\"]\n",
    "err = df_std[\"y\"]\n",
    "if plot_model_bands:\n",
    "    label = r\"Model prediction\"\n",
    "    plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "    for isig, nsig in enumerate(nsigs):\n",
    "        plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "if plot_model_mean:\n",
    "    label = r\"Model prediction\" if not plot_model_bands else None\n",
    "    plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "if plot_training_data:\n",
    "    plt.plot(df[\"x\"], df[\"y\"], \".\", color=\"black\", label=\"Training data\")\n",
    "plt.xlim((0.0, 1.0))\n",
    "plt.xlabel(r\"$X$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deleteing datasets and campaigns**\n",
    "\n",
    "To keep your cloud storage tidy you should delete your datasets and campaigns when you are finished with them. `tl.delete_campaign` and `tl.delete_dataset` only deletes them from the cloud storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataset\n",
    "tl.delete_dataset(dataset_id)\n",
    "\n",
    "# Delete campaign\n",
    "tl.delete_campaign(campaign_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-demos-5eekO54e-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
