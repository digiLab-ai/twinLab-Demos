{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compositional Kernel Search for Gaussian Processes**\n",
    "\n",
    "Despite its importance, choosing the right covariance kernel to use with a Gaussian Process model can be a difficult task. For example, when modelling long-term historical data, one may be interested in local seasonal effects (short-term periodic parts of the signal), as well as long-term global trends.\n",
    "\n",
    "In addition to the commonly chosen kernel functions, the space of possible kernels become very complicated when including _compositional kernels_, such as adding or multiplying two kernels together. For a brief reference on compositional kernels, see [here](https://www.cs.toronto.edu/~duvenaud/cookbook/).\n",
    "\n",
    "The `twinlab` library comes with a feature called _Model Selection_ which automates the process of kernel selection and composition. This algorithm is a mix of two well-known algorithms: [Compositional Kernel Search](https://arxiv.org/pdf/1302.4922.pdf) and [Scalable Structure Discovery](http://proceedings.mlr.press/v84/kim18a/kim18a.pdf).\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "- Compositional Kernel Search in `Campaign`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinlab import\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Formulation**\n",
    "\n",
    "Here, we will design a function with multiple components that may be interest for modelling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The true function\n",
    "def oscillator(x):\n",
    "    return np.cos((x - 5) / 2) * np.sin(10 * x / 5) + x * 0.2\n",
    "\n",
    "\n",
    "X = np.linspace(-15, 15, 100)[:, np.newaxis]\n",
    "y = oscillator(X)  # Arrange outputs as feature columns\n",
    "\n",
    "n_data = 200\n",
    "X_data = np.random.uniform(-10, 10, size=n_data)\n",
    "y_data = oscillator(X_data)\n",
    "\n",
    "plt.plot(X, y)\n",
    "plt.scatter(X_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "df = pd.DataFrame({\"x\": X_data, \"y\": y_data})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset_id = \"ModelSelect_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GP without Model Selection**\n",
    "\n",
    "For a fair comparison, we will want to run a standard GP with the ubiquitous Matern 5/2 kernel first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"BasicGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,  # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": [\n",
    "        \"x\"\n",
    "    ],  # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.75,  # Determine how much data is used for training, here 75% is used to train the model\n",
    "    \"estimator\": \"gaussian_process_regression\",  # and 25% is used to test it.\n",
    "}\n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inference results\n",
    "df_mean, df_stdev = tl.predict_campaign(pd.DataFrame(X, columns=[\"x\"]), campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values\n",
    "\n",
    "plt.fill_between(\n",
    "    X.flatten(),\n",
    "    (y_mean - 1.96 * y_stdev).flatten(),\n",
    "    (y_mean + 1.96 * y_stdev).flatten(),\n",
    "    color=\"k\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "plt.scatter(df[\"x\"], df[\"y\"], alpha=0.5, label=\"Training Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.plot(X, y, c=\"r\", linewidth=2, label=\"True Function\")\n",
    "plt.plot(X, y_mean, c=\"k\", linewidth=2, linestyle=\"dashed\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GP with Model Selection**\n",
    "\n",
    "Model selection in `twinlab` is exposed via the `'model_selection'=True` keyword passed to `tl.train_campaign`. Additional keyword parameters to control the model selection process can be passed to the `'model_selection_kwargs'` dictionary.\n",
    "\n",
    "Important keywords include `'depth'`, which controls the maximum number of compositional kernels to search for, and `'beam'`, which controls the number of successful trials carried between search iterations. `'beam'=1` corresponds to greedy search, and `'beam'=None` corresponds to grid search (this is the default, but will result in exponential computational complexity). It is highly recommended to also provide a `'seed'` keyword parameter to allow reproducibility.\n",
    "\n",
    "Note that the model achieved by this process is no more _correct_ when compared to the basic model (as they are just different ways of describing the same data), however the model with automatic compositional kernel may have better extrapolation properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"ModelSelectionGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,  # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": [\n",
    "        \"x\"\n",
    "    ],  # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.75,  # Determine how much data is used for training, here 75% is used to train the model\n",
    "    \"estimator\": \"gaussian_process_regression\",  # and 25% is used to test it.\n",
    "    \"model_selection\": True,\n",
    "    \"model_selection_kwargs\": {\"depth\": 4, \"beam\": 2, \"seed\": 123},\n",
    "}\n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inference results\n",
    "df_mean, df_stdev = tl.predict_campaign(pd.DataFrame(X, columns=[\"x\"]), campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values\n",
    "\n",
    "plt.fill_between(\n",
    "    X.flatten(),\n",
    "    (y_mean - 1.96 * y_stdev).flatten(),\n",
    "    (y_mean + 1.96 * y_stdev).flatten(),\n",
    "    color=\"k\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "plt.scatter(df[\"x\"], df[\"y\"], alpha=0.5, label=\"Training Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.plot(X, y, c=\"r\", linewidth=2, label=\"True Function\")\n",
    "plt.plot(X, y_mean, c=\"k\", linewidth=2, linestyle=\"dashed\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaigns and dataset\n",
    "tl.delete_campaign(\"BasicGP\")\n",
    "tl.delete_campaign(\"ModelSelectionGP\")\n",
    "\n",
    "tl.delete_dataset(dataset_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-T1BT2Sfn-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
