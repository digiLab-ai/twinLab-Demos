{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from time import time\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataset_id = \"timings\"\n",
    "campaign_id = dataset_id\n",
    "err_sig = 0.25\n",
    "n = 100\n",
    "random_seed = 42\n",
    "use_cloud = True\n",
    "n_cycle = 1\n",
    "n_warm = 10\n",
    "ns_train = [10*np.power(2, i) for i in range(10)]\n",
    "ns_eval = [10*np.power(2, i) for i in range(10)]\n",
    "\n",
    "# Training parameters\n",
    "params = {\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"inputs\": [\"X\"],\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 1.,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random-number generator\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Warm up lambdas to ensure fair tests\n",
    "# if use_cloud:\n",
    "#     df_warm= pd.DataFrame({'X': np.random.rand(n_warm), 'y': np.random.rand(n_warm)})\n",
    "#     tl.upload_dataset(df_warm, dataset_id)\n",
    "#     tl.train_campaign(params, campaign_id)\n",
    "#     tl.predict_campaign(df_warm, campaign_id)\n",
    "#     tl.delete_campaign(campaign_id)\n",
    "#     tl.delete_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over numbers of training data\n",
    "dict_upload = {\"n\": [], \"t [s]\": []}\n",
    "dict_train = {\"n\": [], \"t [s]\": []}\n",
    "dict_eval = {\"n_train\": [], \"n_eval\": [], \"t [s]\": []}\n",
    "\n",
    "# df_small = None\n",
    "for n_train in ns_train:\n",
    "\n",
    "    # Create training data\n",
    "    X = np.random.rand(n_train)\n",
    "    y = np.sin(X*2.*np.pi*n_cycle)+np.random.normal(0., err_sig, n_train)\n",
    "    df_train = pd.DataFrame({'X': X, 'y': y})\n",
    "    # if df_small is None:\n",
    "    #     df_small = df_train.copy()\n",
    "\n",
    "    # Upload data\n",
    "    if use_cloud: # Warm-up lambda\n",
    "        tl.upload_dataset(df_train, dataset_id)\n",
    "    if use_cloud:\n",
    "        t_start = time()\n",
    "        tl.upload_dataset(df_train, dataset_id)\n",
    "        t_upload = time()-t_start\n",
    "        dict_upload[\"n\"].append(n_train); dict_upload[\"t [s]\"].append(t_upload)\n",
    "        print(f\"Uploading {n_train} data points took {t_upload:.2f} seconds\")\n",
    "\n",
    "    # Train\n",
    "    if use_cloud: # Warm-up lambda\n",
    "        tl.train_campaign(params, campaign_id)\n",
    "    t_start = time()\n",
    "    if use_cloud:\n",
    "        tl.train_campaign(params, campaign_id)\n",
    "    else:\n",
    "        raise NotImplementedError(\"twinLab local not implemented yet\")\n",
    "    t_train = time()-t_start\n",
    "    dict_train[\"n\"].append(n_train); dict_train[\"t [s]\"].append(t_train)\n",
    "    print(f\"Training on {n_train} data points took {t_train:.2f} seconds\")\n",
    "\n",
    "    # Loop over number of test data\n",
    "    for n_eval in ns_eval:\n",
    "\n",
    "        # Create evaluation data\n",
    "        X = np.random.rand(n_eval)\n",
    "        df_eval = pd.DataFrame({\"X\": X})\n",
    "\n",
    "        # Predict\n",
    "        if use_cloud: # Warm-up lambda\n",
    "            _, _ = tl.predict_campaign(df_eval, campaign_id)\n",
    "        t_start = time()\n",
    "        if use_cloud:\n",
    "            _, _ = tl.predict_campaign(df_eval, campaign_id)\n",
    "        else:\n",
    "            raise NotImplementedError(\"twinLab local not implemented yet\")\n",
    "        t_predict = time()-t_start\n",
    "        dict_eval[\"n_train\"].append(n_train); dict_eval[\"n_eval\"].append(n_eval); dict_eval[\"t [s]\"].append(t_predict)\n",
    "        print(f\"Predicting {n_eval} data points took {t_predict:.2f} seconds\")\n",
    "    print()\n",
    "\n",
    "    # Delete campaign\n",
    "    if use_cloud:\n",
    "        tl.delete_campaign(campaign_id)\n",
    "\n",
    "# Delete dataset\n",
    "if use_cloud:\n",
    "    tl.delete_dataset(dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot upload data times\n",
    "if use_cloud:\n",
    "    logx, logy = True, True\n",
    "    df_upload = pd.DataFrame(dict_upload)\n",
    "    plt.scatter(df_upload[\"n\"], df_upload[\"t [s]\"])\n",
    "    plt.xlabel(\"number of data points\")\n",
    "    plt.ylabel(\"upload time [s]\")\n",
    "    if logx:\n",
    "        plt.xscale(\"log\")\n",
    "    else:\n",
    "        plt.xlim(left=0.)\n",
    "    if logy:\n",
    "        plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.ylim(bottom=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training times\n",
    "logx, logy = True, True\n",
    "df_train = pd.DataFrame(dict_train)\n",
    "plt.scatter(df_train[\"n\"], df_train[\"t [s]\"])\n",
    "plt.xlabel(\"number of data points\")\n",
    "plt.ylabel(\"training time [s]\")\n",
    "if logx:\n",
    "    plt.xscale(\"log\")\n",
    "else:\n",
    "    plt.xlim(left=0.)\n",
    "if logy:\n",
    "    plt.yscale(\"log\")\n",
    "else:\n",
    "    plt.ylim(bottom=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evaluation times\n",
    "logx, logy = True, True\n",
    "df_eval = pd.DataFrame(dict_eval)\n",
    "plt.scatter(df_eval[\"n_eval\"], df_eval[\"t [s]\"], c=df_eval[\"n_train\"], cmap=\"inferno_r\", norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(label=\"number of training points\")\n",
    "plt.xlabel(\"number of evaluation data points\")\n",
    "plt.ylabel(\"prediction time [s]\")\n",
    "if logx:\n",
    "    plt.xscale(\"log\")\n",
    "else:\n",
    "    plt.xlim(left=0.)\n",
    "if logy:\n",
    "    plt.yscale(\"log\")\n",
    "else:\n",
    "    plt.ylim(bottom=0.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-cloud-IBHCqXSr-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
