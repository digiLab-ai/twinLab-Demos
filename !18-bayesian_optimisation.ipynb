{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bayesian Optimization**\n",
    "\n",
    "Using `twinLab`, we can easily build a surrogate model of some real-world physical processes using limited experimental data. The discrepancy between this surrogate model and the real process is described by the (calibrated) uncertainty estimate produced our models. This way, inference activities while using the surrogate model can be supported by well-grounded evidence of the model *correctness*. In areas of high model uncertainty, one must then take care to not be overly trusting of the model output, which is especially important for safety-critical applications.\n",
    "\n",
    "In some scenarios, there may be a requirement to find the value that maximizes an objective function(that is not available but we know this function generated the data points in our training data). `twinLab` offers the feature of finding the maximising values for a given function. This can be done once the model is fitted to the training data. The acquisition function `qEI` (Monte Carlo Expected Improvement) is used to find the value that maximizes an objective function using the Gaussian process trained on training data using `twinLab`. \n",
    "\n",
    "This notebook will cover:\n",
    "- Finding the maxima of an unknown function using `twinLab` from the data points generated by the unknown function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinLab import\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1-Dimensional example**\n",
    "\n",
    "We first begin with a one-dimensional example. Consider the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "# Target function: forrester function\n",
    "def f(x, a=6, b=12):\n",
    "    return -(a*x - 2)**2 * np.sin(b*x -4)\n",
    "\n",
    "X = np.linspace(0,1,100)[:,np.newaxis]\n",
    "y = f(X) # Arrange outputs as feature columns\n",
    "\n",
    "# Set up training data dataframe \n",
    "n_train = 10\n",
    "X_data = np.random.uniform(0, 1, size=n_train)\n",
    "y_data = f(X_data) + np.random.normal(scale=0.1, size=X_data.shape)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5.5, 4.5))\n",
    "plt.plot(X,y, label=\"Target Function\")\n",
    "plt.scatter(X_data, y_data, color=\"red\", label=\"Training Data\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Quantity of Interest\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset and upload it to the twinLab cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_train = pd.DataFrame({'X': X_data, 'y': y_data})\n",
    "df_test = pd.DataFrame({'X': X.flatten(), 'y': y.flatten()})\n",
    "\n",
    "# Define the name of the dataset\n",
    "dataset_id = \"Training_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_train, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a training campaign to train the model and make predictions on test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"BasicGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,                   \n",
    "    \"inputs\": [\"X\"],                          \n",
    "    \"outputs\": [\"y\"],\n",
    "}                                        \n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)\n",
    "\n",
    "# Inference on test data\n",
    "df_mean, df_stdev = tl.predict_campaign(df_test, campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model's mean prediction and the model's confidence interval around the given data points to visualise how closely the model represents the target function that generated the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 4.5))\n",
    "plt.fill_between(X.flatten(), \n",
    "                 (y_mean - 2.58*y_stdev).flatten(), \n",
    "                 (y_mean + 2.58*y_stdev).flatten(), \n",
    "                 color='C0', alpha=0.25, label=\"Model Confidence Interval\")\n",
    "plt.plot(X, y_mean, c='C0', linewidth=2, label=\"Model Mean Prediction\")\n",
    "\n",
    "plt.scatter(df_train['X'], df_train['y'], color=\"red\", label=\"Training data\")\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "\n",
    "plt.plot(X, y, c='r', linewidth=2, linestyle='dashed', label=\"Target Function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have an initial model with which we can try to sample a datapoint that the model thinks is the maxima of the objective function with its current knowledge of the hidden function(that we know in this case!). This is done by the `optimise_campaign` function in twinLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max = tl.optimise_campaign(\"BasicGP\", num_points=1)\n",
    "df_max['y'] = f(df_max['X'].values) + np.random.normal(scale=0.1, size=1)\n",
    "print(df_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model's mean prediction, confidence interval, the training data and the maxima candidate for the target function that was generated by `optimise_campaign`. \n",
    "It can be seen that the point sampled by this function is a maxima of the target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 4.5))\n",
    "plt.fill_between(X.flatten(), \n",
    "                 (y_mean - 2.58*y_stdev).flatten(), \n",
    "                 (y_mean + 2.58*y_stdev).flatten(), \n",
    "                 color='C0', alpha=0.25, label=\"Model Confidence Interval\")\n",
    "plt.plot(X, y_mean, c='C0', linewidth=2, label=\"Model Mean Prediction\")\n",
    "\n",
    "plt.scatter(df_train['X'], df_train['y'], color=\"red\", label=\"Training data\")\n",
    "plt.scatter(df_max['X'], df_max['y'], color=\"black\", label=\"Local maxima\")\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "\n",
    "plt.plot(X, y, c='r', linewidth=2, linestyle='dashed', label=\"Target Function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optimise for this function again to extract better maxima candidates using the `optimise_campaign` method. To do this, we just need to re-run this method again with the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_new = tl.optimise_campaign(\"BasicGP\", num_points=1)\n",
    "df_max_new['y'] = f(df_max_new['X'].values) + np.random.normal(scale=0.1, size=1)\n",
    "print(df_max_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can once again plot the results to visualise the mean prediction of the model, the confidence interval of the model, the target function, the data points and the newly extracted candidate point for the maxima. The plots might almost look the same, and the improvement(if any) in the optimisation process can be observed from the 'y' value for the new point. Optimisation over an objective function is an iterative process. This may require running the `optimise_campaign` method multiple times to achieve a better estimate of the maxima of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 4.5))\n",
    "plt.fill_between(X.flatten(), \n",
    "                 (y_mean - 2.58*y_stdev).flatten(), \n",
    "                 (y_mean + 2.58*y_stdev).flatten(), \n",
    "                 color='C0', alpha=0.25, label=\"Model Confidence Interval\")\n",
    "plt.plot(X, y_mean, c='C0', linewidth=2, label=\"Model Mean Prediction\")\n",
    "\n",
    "plt.scatter(df_train['X'], df_train['y'], color=\"red\", label=\"Training data\")\n",
    "plt.scatter(df_max_new['X'], df_max_new['y'], color=\"black\", label=\"Local maxima candidate\")\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "\n",
    "plt.plot(X, y, c='r', linewidth=2, linestyle='dashed', label=\"Target Function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the campaign and the dataset if required from the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the campaign and dataset\n",
    "tl.delete_campaign(\"BasicGP\")\n",
    "tl.delete_dataset(\"Training_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2-Dimensional Example**\n",
    "\n",
    "In the previous one-dimensional example, the model sampled a point that was a maxima of the target function. This is a very good educated guess for a maxima that the model is making given the very small number of training data points. We can now also see how this works for a 2D example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple 2D quadratic function\n",
    "def quadratic(x, y):\n",
    "    return -((x - 1) ** 2 + (y - 2) ** 2) \n",
    "\n",
    "# Plotting function\n",
    "def plot_function(\n",
    "    xx, yy, zz,  # Background grid\n",
    "    zz_pred=None, zz_stdv=None, # Mean and uncertainty in model function\n",
    "    x_org=None, y_org=None, z_org=None,  # Original training data\n",
    "    x_max=None, y_max=None,  # Proposed candidate points for maxima\n",
    "    show_truth=True,  # Show true function\n",
    "    ):\n",
    "\n",
    "    cmap_fn, cmap_std = 'YlGn', 'Blues'\n",
    "    alpha_fn, alpha_std = 0.8, 1.\n",
    "    levels = 20\n",
    "    color_org, color_max = 'black', 'red'\n",
    "    marker_org, marker_max = 'x', 'o'\n",
    "    marker_col = 'o'\n",
    "    vmin, vmax = zz.min(), zz.max()\n",
    "    figx, figy = 4, 4\n",
    "\n",
    "    # Set layout\n",
    "    if zz_pred is None and zz_stdv is None:\n",
    "        rows, cols = 1, 1\n",
    "    else:\n",
    "        rows, cols = 1, 3\n",
    "    _, axs = plt.subplots(rows, cols, figsize=(cols*figx, rows*figy))\n",
    "\n",
    "    if rows == 1 and cols == 1:\n",
    "        axs = np.array([axs])\n",
    "    axs = np.atleast_2d(axs)\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xticks([]), ax.set_yticks([])\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    # Plot true function\n",
    "    if show_truth:\n",
    "        axs[0, 0].set_title('True function')\n",
    "        axs[0, 0].contourf(xx, yy, zz, cmap=cmap_fn, levels=levels, alpha=alpha_fn, vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        axs[0, 0].set_title('True function (unknown)')\n",
    "        axs[0, 0].set_facecolor('lightgrey')\n",
    "    \n",
    "    if x_org is not None and y_org is not None and z_org is not None: # Plot original points\n",
    "        if show_truth:\n",
    "            axs[0, 0].scatter(x_org, y_org, c=color_org, marker=marker_org, label='Original samples')\n",
    "            axs[0, 1].scatter(x_org, y_org, c=color_org, marker=marker_org, label='Original samples')\n",
    "            axs[0, 2].scatter(x_org, y_org, c=color_org, marker=marker_org, label='Original samples')\n",
    "        else:\n",
    "            pass\n",
    "            axs[0, 0].scatter(x_org, y_org, c=z_org, marker=marker_col, cmap=cmap_fn, vmin=vmin, vmax=vmax, label='Original samples')\n",
    "        axs[0, 0].legend(loc=\"upper left\")\n",
    "\n",
    "    # Plot mean prediction\n",
    "    if zz_pred is not None and zz_stdv is not None:\n",
    "        axs[0, 1].set_title('Model function')\n",
    "        axs[0, 1].contourf(xx, yy, zz_pred, cmap=cmap_fn, levels=levels, alpha=alpha_fn, vmin=vmin, vmax=vmax)\n",
    "        axs[0, 2].set_title('Model uncertainty')\n",
    "        axs[0, 2].contourf(xx, yy, zz_stdv, cmap=cmap_std, levels=levels, alpha=alpha_std)\n",
    "        if x_org is not None: # Plot original points\n",
    "            axs[0, 1].scatter(x_org, y_org, c=color_org, marker=marker_org)\n",
    "            axs[0, 2].scatter(x_org, y_org, c=color_org, marker=marker_org)\n",
    "            if rows == 2:\n",
    "                axs[1, 1].scatter(x_org, y_org, c=color_org, marker=marker_org)\n",
    "                axs[1, 2].scatter(x_org, y_org, c=color_org, marker=marker_org)\n",
    "        if x_max is not None: # Plot candidate points for maxima\n",
    "            axs[0, 0].scatter(x_max, y_max, c=color_max, marker=marker_max, label='Maximum candidate')\n",
    "            axs[0, 1].scatter(x_max, y_max, c=color_max, marker=marker_max, label='Maximum candidate')\n",
    "            axs[0, 2].scatter(x_max, y_max, c=color_max, marker=marker_max, label='Maximum candidate')\n",
    "            axs[0, 0].legend(loc=\"upper left\")\n",
    "            axs[0, 1].legend(loc=\"upper left\")\n",
    "            axs[0, 2].legend(loc=\"upper left\")\n",
    "            if rows == 2:\n",
    "                axs[1, 2].scatter(x_max, y_max, c=color_max, marker=marker_max)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the 2D target function. This function has a maximum at (x*, y*) = (1, 2) and f(x*, y*) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "nmesh = 101\n",
    "\n",
    "# Define ranges for plotting\n",
    "xmin, xmax = -10, 10\n",
    "ymin, ymax = -10, 10\n",
    "# Generate x and y values\n",
    "xx = np.linspace(xmin, xmax, nmesh)\n",
    "yy = np.linspace(ymin, ymax, nmesh)\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "zz = quadratic(xx, yy)\n",
    "\n",
    "# Generate noisy train data\n",
    "n_train = 15\n",
    "err = 0.1\n",
    "x_train = np.random.uniform(xmin, xmax, n_train)\n",
    "y_train = np.random.uniform(ymin, ymax, n_train)\n",
    "z_train = np.random.normal(quadratic(x_train, y_train), err, n_train)\n",
    "\n",
    "# Number of new data points to generate each iteration\n",
    "num_points = 1\n",
    "\n",
    "# Plot the data points\n",
    "plot_function(xx, yy, zz, x_org=x_train, y_org=y_train)\n",
    "\n",
    "# Convert to dataframes\n",
    "df_train = pd.DataFrame({'x': x_train.flatten(), 'y': y_train.flatten(), 'z': z_train.flatten()})\n",
    "df_test = pd.DataFrame({'x': xx.flatten(), 'y': yy.flatten(), 'z': zz.flatten()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset_id = \"2D_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_train, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a training campaign, train the model and predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"2D_GP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,                  \n",
    "    \"inputs\": ['x','y'],                        \n",
    "    \"outputs\": ['z'],\n",
    "}                                        \n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)\n",
    "\n",
    "# Inference on test data\n",
    "df_mean, df_stdev = tl.predict_campaign(df_test, campaign_id)\n",
    "y_mean, y_stdev = df_mean.values, df_stdev.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now try to sample a point using the `optimise_campaign` method in twinLab and try to visualise it alongside the original training samples on 2D contours of the true function and the model function. It can be seen that the sampled candidate point is very close to the true maximum of the target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_mean, df_stdev = tl.predict_campaign(df_test, campaign_id)\n",
    "z_mean, z_stdv = df_mean.values, df_stdev.values\n",
    "\n",
    "x_org, y_org, z_org = df_train['x'].values, df_train['y'].values, df_train['z'].values\n",
    "\n",
    "# Get candidate points for maxima of the true function using optimise_campaign\n",
    "df_max = tl.optimise_campaign(\"2D_GP\", num_points=1)\n",
    "df_max['z'] = quadratic(df_max['x'].values, df_max['y'].values) + np.random.normal(scale=0.1, size=1)\n",
    "print(df_max)\n",
    "\n",
    "\n",
    "# Plot sample location\n",
    "plot_function(xx, yy, zz, \n",
    "                    z_mean.reshape((nmesh, nmesh)), z_stdv.reshape((nmesh, nmesh)),\n",
    "                    x_org=x_org, y_org=y_org, z_org=z_org,\n",
    "                    x_max=df_max['x'].values, y_max=df_max['y'].values,\n",
    "                    show_truth=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optimise once again to see if we can achieve a better value for the maxima. We run the `optimise_campaign` method again. Any improvement can be noted from the z value printed. The plots might look almost similar due to marginal changes in the values of the new candidate point obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise once again using optimise_campaign\n",
    "df_max_new = tl.optimise_campaign(\"2D_GP\", num_points=1)\n",
    "df_max_new['z'] = quadratic(df_max_new['x'].values, df_max_new['y'].values) + np.random.normal(scale=0.1, size=1)\n",
    "print(df_max_new)\n",
    "\n",
    "\n",
    "# Plot sample location\n",
    "plot_function(xx, yy, zz, \n",
    "                    z_mean.reshape((nmesh, nmesh)), z_stdv.reshape((nmesh, nmesh)),\n",
    "                    x_org=x_org, y_org=y_org, z_org=z_org,\n",
    "                    x_max=df_max_new['x'].values, y_max=df_max_new['y'].values,\n",
    "                    show_truth=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the training datasets and the training campaigns from the cloud if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaign and dataset\n",
    "tl.delete_campaign(campaign_id)\n",
    "tl.delete_dataset(\"2DData\")\n",
    "tl.delete_dataset(\"Training_Data\")\n",
    "tl.delete_dataset(\"New_Points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-demos-FtgrNg4r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
