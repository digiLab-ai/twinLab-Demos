{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Quickstart Guide\n",
    "\n",
    "This tutorial fllows the same formoat as `Quickstart Guide` but explores further functionality provided by twinLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API setup\n",
    "\n",
    "When you first use twinLab you will have to set your API and server url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key\n",
    "tl.set_api_key(\"my_api_key\")\n",
    "\n",
    "# Set the server url\n",
    "tl.set_server_url(\"http://twinlab.digilab.co.uk/prod\")\n",
    "\n",
    "# Check which url is being used\n",
    "tl.get_server_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your twinLab information\n",
    "\n",
    "Confirm your twinLab version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.get_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or view your user infomration including how many credits you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.get_user_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a dataset\n",
    "\n",
    "twinLab requires datasets to be uploaded to the cloud with a `dataset_id`. This is what the data is saved as in the cloud and how models are able to access the data for training. Data can be uploaded in the form of a `pandas` dataframes directly from your code.\n",
    "\n",
    "> üìù **Note:** Your dataset must have column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.6964691855978616,\n",
    "0.28613933495037946,\n",
    "0.2268514535642031,\n",
    "0.5513147690828912,\n",
    "0.7194689697855631,\n",
    "0.42310646012446096,\n",
    "0.9807641983846155,\n",
    "0.6848297385848633,\n",
    "0.48093190148436094,\n",
    "0.3921175181941505]\n",
    "\n",
    "y = [-0.8173739564129022,\n",
    "0.8876561174050408,\n",
    "0.921552660721474,\n",
    "-0.3263338765412979,\n",
    "-0.8325176123242133,\n",
    "0.4006686354731812,\n",
    "-0.16496626502368078,\n",
    "-0.9607643657025954,\n",
    "0.3401149876855609,\n",
    "0.8457949914442409]\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "display(df)\n",
    "\n",
    "dataset_id = \"example_data\"\n",
    "\n",
    "# Upload dataset using a local dataframe\n",
    "tl.upload_dataset(df, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively data can be upload directly from a csv by using a filepath. The filepath string is input into `tl.upload_dataset` in the exact same place the dataframe was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepath = \"example_data_folder/example_data.csv\"\n",
    "\n",
    "dataset_id = \"example_data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df_filepath, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View datasets\n",
    "\n",
    "Once a dataset has been upload it can be easily acccesed using built in twinLab functions. A list of all uploaded dataset can be produced, individual datasets can be printed and you can even querey a dataset to get a statistical summary of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all uploaded datasets\n",
    "tl.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data within the dataset\n",
    "tl.view_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querey the dataset to get a statistical summary\n",
    "tl.query_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a campaign\n",
    "\n",
    "The `campaign` class is used to train and implement your surrogate models. As with the dataset an id is defined, this is what the model will be saved as in the cloud. When training a model the arguments are passed using a dictionary; here that dictionary is called `campaign_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_id = \"example_campaign\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": \"example_data\",   # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": [\"x\"],                # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 0.8         # Determine how much data is used for training, here 80% is used to tran the model  \n",
    "}                                   # and 20% is used to test it.     \n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View campaigns\n",
    "\n",
    "Just as with datasets all saved campaigns can be listed and queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List campaigns\n",
    "tl.list_campaigns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a campaigns parameters\n",
    "tl.view_campaign(campaign_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the status of a campaign\n",
    "tl.query_campaign(campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a predict campaign\n",
    "\n",
    "The surrogate model is now trained and saved to the cloud under the campaign_id. It can now be used to make predictions. First an evaluation dataset containing only inputs is defined, as the campaign will provide the outputs. This can be done using a local pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = np.linspace(0,1,128)\n",
    "\n",
    "df_eval = pd.DataFrame({'x':x_eval})\n",
    "display(df_eval)\n",
    "\n",
    "df_mean, df_std = tl.predict_campaign(df_eval, campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively the evaluation dataset can be uploaded driectly from a csv by using a filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_filepath = \"example_data_folder/example_eval_data.csv\"\n",
    "\n",
    "df_mean, df_std = tl.predict_campaign(df_eval, campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results\n",
    "`tl.predict_campaign` outputs mean values for each input and their standard deviation; this gives the abilty to nicely visualise the uncertainty in results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "# nsigs = [0.674, 1.960, 2.576]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "# Plot results\n",
    "grid = df_eval[\"x\"]\n",
    "mean = df_mean[\"y\"]\n",
    "err = df_std[\"y\"]\n",
    "if plot_model_bands:\n",
    "    label = r\"Model prediction\"\n",
    "    plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "    for isig, nsig in enumerate(nsigs):\n",
    "        plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "if plot_model_mean:\n",
    "    label = r\"Model prediction\" if not plot_model_bands else None\n",
    "    plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "if plot_training_data:\n",
    "    plt.plot(df[\"x\"], df[\"y\"], \".\", color=\"black\", label=\"Training data\")\n",
    "plt.xlim((0.0, 1.0))\n",
    "plt.xlabel(r\"$X$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a sample campaign\n",
    "\n",
    "The `tl.sample_campaign` function can be used to retrieve any number of results from your model. It requires the inputs for which you want the values and how many to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample inputs\n",
    "sample_inputs = pd.DataFrame({'x': np.linspace(0,1,20)})\n",
    "\n",
    "# Define number of samples to calculate for each input\n",
    "num_samples = 3\n",
    "\n",
    "sample_result = tl.sample_campaign(sample_inputs, campaign_id, num_samples)\n",
    "\n",
    "# View the results in the form of a fataframe\n",
    "display(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results\n",
    "\n",
    "The results can be plotted over the top of the previous graph giving a nice visualisation of the sampled data, with the model's uncertainity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "# nsigs = [0.674, 1.960, 2.576]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "# Plot results\n",
    "grid = df_eval[\"x\"]\n",
    "mean = df_mean[\"y\"]\n",
    "err = df_std[\"y\"]\n",
    "if plot_model_bands:\n",
    "    label = r\"Model prediction\"\n",
    "    plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "    for isig, nsig in enumerate(nsigs):\n",
    "        plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "if plot_model_mean:\n",
    "    label = r\"Model prediction\" if not plot_model_bands else None\n",
    "    plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "if plot_training_data:\n",
    "    plt.plot(df[\"x\"], df[\"y\"], \".\", color=\"#1d1d1b\", label=\"Training data\")\n",
    "for i in range(num_samples):\n",
    "    plt.scatter(sample_inputs, data[:,i], marker='x', s=9, c='#ffb500')\n",
    "plt.scatter([], [], marker='x', s=9, c='#ffb500', label='Sampled Points')\n",
    "plt.xlim((0.0, 1.0))\n",
    "plt.xlabel(r\"$X$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-demos-5eekO54e-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
