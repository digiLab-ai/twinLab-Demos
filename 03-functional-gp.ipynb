{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gaussian Process Campaign with Functional Data**\n",
    "\n",
    "In many scenarios, we may be dealing with *functional* data. This means that the input, output, or both, are sampled over a particular dimension (e.g. time). In `twinlab`, data are presented in column-feature format, meaning a single data sample of functional format may contain hundreds or thousands of columns. \n",
    "\n",
    "Gaussian Process models do not scale well to these scenarios, so we provide the ability to perform dimensionality reduction before model fitting. \n",
    "\n",
    "This notebook will cover:\n",
    "- How to decompose functional inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "# twinLab import\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Formulation**\n",
    "Here, we define a problem with two input dimensions and one functional output defined over a grid of sample locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid over which the functional output is defined\n",
    "grid = np.linspace(0, 1)\n",
    "\n",
    "# True function: Forrester function with variable a and b\n",
    "def model(x):\n",
    "    return (x[0] * grid - 2) ** 2 * np.sin(x[1] * grid - 4)\n",
    "\n",
    "# Define input data\n",
    "x = np.random.uniform(size=(100, 2))\n",
    "x[:, 0] = x[:, 0] * 4 + 4\n",
    "x[:, 1] = x[:, 1] * 4 + 10\n",
    "\n",
    "# Compute output data\n",
    "y = np.zeros((x.shape[0], grid.size))\n",
    "\n",
    "for i, x_i in enumerate(x):\n",
    "    y[i, :] = model(x_i)\n",
    "\n",
    "y = {\"y_{}\".format(i): y[:, i] for i in range(grid.size)}\n",
    "\n",
    "# Save to DataFrame\n",
    "df = pd.DataFrame({\"x1\": x[:, 0], \"x2\": x[:, 1], **y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset_id = \"FunctionalGP_Data\"\n",
    "\n",
    "# Upload the dataset to the cloud\n",
    "tl.upload_dataset(df, dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functional Campaign Workflow**\n",
    "\n",
    "In `twinlab`, dimensionality reduction is implemented in the form of truncated Singular Value Decomposition (tSVD), and is accessible via the convenience keyword parameters `decompose_inputs` and `decompose_outputs`, and the ratio of retained singular components are controlled by the keywords `input_explained_variance` and `output_explained_variance`.\n",
    "\n",
    "One can decompose the inputs, outputs, or both in the same `Campaign`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise campaign\n",
    "campaign_id = \"FunctionalGP\"\n",
    "\n",
    "campaign_params = {\n",
    "    \"dataset_id\": dataset_id,                   # This points the campaign to the uploaded dataset\n",
    "    \"inputs\": list(df.columns[:2]),             # Using the datasets column headers define the input and output data\n",
    "    \"outputs\": list(df.columns[2:]),\n",
    "    \"test_train_ratio\": 0.75,                   # Determine how much data is used for training, here 75% is used to train the model  \n",
    "    \"estimator\": \"gaussian_process_regression\", # and 25% is used to test it.\n",
    "    \"decompose_inputs\": False,                  # Whether to reduce input dimensions\n",
    "    \"input_explained_variance\": 0.99,           # Keep 99% of variance information in the data\n",
    "    \"decompose_outputs\": True,                  # Whether to reduce output dimensions\n",
    "    \"output_explained_variance\": 0.99999,\n",
    "}                                        \n",
    "\n",
    "# Start a new campaign and train a surrogate model\n",
    "tl.train_campaign(campaign_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of output plots\n",
    "grid = np.linspace(0, 1)\n",
    "\n",
    "x1 = [4, 6, 8]\n",
    "x2 = [10, 12, 14]\n",
    "\n",
    "X = np.array(list(product(x1, x2)))\n",
    "ax_i = list(product([0, 1, 2], [0, 1, 2]))\n",
    "\n",
    "# Create output plot and save in directory\n",
    "fig, axes = plt.subplots(figsize=(14, 12), nrows=3, ncols=3)\n",
    "\n",
    "# Setup legend\n",
    "legend_labels = {}\n",
    "\n",
    "for i, x_i in enumerate(X):\n",
    "    r, c = ax_i[i]\n",
    "    ax = axes[r, c]\n",
    "\n",
    "    X_test = pd.DataFrame(x_i[np.newaxis, :], columns=[\"x1\", \"x2\"])\n",
    "    y_test = model(X_test.values.flatten())\n",
    "\n",
    "    y_mean, y_stdev = tl.predict_campaign(X_test, campaign_id)\n",
    "    y_mean = y_mean.values\n",
    "    y_stdev = y_stdev.values\n",
    "\n",
    "    ax.set_title(\"a = {}, b = {}\".format(x_i[0], x_i[1]))\n",
    "    ax.plot(grid, y_mean.flatten(), c=\"k\")\n",
    "    ax.plot(grid, y_test.flatten(), c=\"red\", linestyle=\"dashed\")\n",
    "    ax.fill_between(\n",
    "        grid,\n",
    "        (y_mean - 1.96 * y_stdev).flatten(),\n",
    "        (y_mean + 1.96 * y_stdev).flatten(),\n",
    "        color=\"k\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "# Store labels for the legend\n",
    "legend_labels[f\"Prediction\"] = plt.Line2D([0], [0], color=\"k\")\n",
    "legend_labels[f\"True Function\"] = plt.Line2D([0], [0], color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "# Print legend\n",
    "fig.legend(legend_labels.values(), legend_labels.keys(), loc=\"upper left\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaign and dataset\n",
    "tl.delete_campaign(campaign_id)\n",
    "\n",
    "tl.delete_dataset(dataset_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-T1BT2Sfn-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
