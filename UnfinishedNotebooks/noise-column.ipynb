{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how a model is degraded if data is used in training that contains no additional information that is useful in prediction. In the training data, $y=\\sin(X_1)$, with some added noise. However, an additional feature $X_2$, has no correlation with $y$ whatsoever, and is just noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries: `numpy` allows us to efficiently manipulate arrays of numerical data; `pandas` gives us access to `DataFrames` which are a way of storing tabular data in `Python` and is the format used by `twinLab`. `matplotlib.pyplot` is used for plotting. `twinlab` is the machine-learning library we are using. Some of the libraries are renamed using `as` for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the top of this cell we define the name of our dataset and model. Because we are using random numbers here we also seed the random generator, so that our results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"noise\"\n",
    "campaign_id = dataset_id\n",
    "\n",
    "random_seed = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some data\n",
    "- $X_1$ and $X_2$ are both arrays of random values between 0 and 1.\n",
    "- $y$ is $\\sin(X_1)$ and, crucially, has no dependency on $X_2$ whatsoever. \n",
    "\n",
    "At the bottom of the cell we put these arrays into a Pandas `DataFrame` with the corresponding column headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random-number generator\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "#Training Data\n",
    "X1 = np.random.rand(10)\n",
    "X2 = np.random.rand(10)\n",
    "y = np.sin(X1*2.*np.pi) + np.random.normal(0, 0.05, 10)\n",
    "\n",
    "train_data = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "display(train_data)\n",
    "\n",
    "tl.upload_dataset(train_data, dataset_id, verbose=True)\n",
    "tl.list_datasets(verbose=True)\n",
    "tl.query_dataset(dataset_id, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we set the parameters to be used for training the machine-learning model. By default, all the data is used in training the model and a Gaussian process is trained. We need to provide the id of the dataset on the `twinLab` cloud and the columns of this that should be taken as inputs `X` and outputs `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines parameters for our prediction\n",
    "prediction_params = {\n",
    "    \"filename\": dataset_id,\n",
    "    \"inputs\" : [\"X1\", \"X2\"],\n",
    "    \"outputs\": [\"y\"],\n",
    "    \"test_train_ratio\": 1.,\n",
    "}\n",
    "\n",
    "tl.train_campaign(prediction_params, campaign_id, verbose=True)\n",
    "tl.list_campaigns(verbose=True)\n",
    "tl.query_campaign(campaign_id, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create values for the model to predict outputs for. Both $X_1$ and $X_2$ are 101 linearly-spaced numbers between 0 and 1.\n",
    "\n",
    "We now create a `pandas` `DataFrame` with data to be used for model evaluation/prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"X1\": np.linspace(0, 1, 101),\n",
    "    \"X2\": np.linspace(0, 1, 101),\n",
    "}\n",
    "prediction_inputs = pd.DataFrame(input_dict)\n",
    "display(prediction_inputs)\n",
    "\n",
    "df_mean, df_std = tl.predict_campaign(prediction_inputs, campaign_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we first plot on a graph the $X_1$ against $y$, then $X_2$ against $y$. \n",
    "- The black dots on the graph are the training data we gave it. \n",
    "- The darkest blue line in the graph is the `df_mean` value.\n",
    "- The blue sections either side represent the range of uncertainty in the `df_mean` value.\n",
    "\n",
    "On the first graph ($X_1$ against $y$), the model has become more uncertain about its predictions of $y$ because of the introduction of $X_2$\n",
    "On the second graph, we can see there is no correlation between $X_2$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "for X, Xlabel in zip([\"X1\", \"X2\"], [\"$X_1$\", \"$X_2$\"]):\n",
    "# Plot results\n",
    "    grid = prediction_inputs[X]\n",
    "    mean = df_mean[\"y\"]\n",
    "    err = df_std[\"y\"]\n",
    "    if plot_model_bands:\n",
    "        label = \"Model prediction\"\n",
    "        plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "        for isig, nsig in enumerate(nsigs):\n",
    "            plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "    if plot_model_mean:\n",
    "        label = \"Model prediction\" if not plot_model_bands else None\n",
    "        plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "    if plot_training_data:\n",
    "        plt.plot(train_data[X], train_data[\"y\"], \".\", color=\"black\", label=\"Training data\")\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.xlabel(Xlabel)\n",
    "    plt.ylabel(\"$y$\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clean up and delete the campaign and dataset (if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.delete_campaign(campaign_id, verbose=True)\n",
    "tl.delete_dataset(dataset_id, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-cloud-IBHCqXSr-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
